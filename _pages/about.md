---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hey, this is Sadra! I‚Äôm currently studying my PhD in Computer Science at USC, working at the intersection of Human-Computer Interaction (HCI) and Natural Language Processing (NLP), i.e., making LLMs better friends of humans.
My current research focuses on helping people make better decisions using LLMs.
On the side (and honestly, all the time), I build and maintain scientific software tools with a great team of open-source enthusiasts.
I‚Äôm always looking for ways to make technology and science more accessible, and fun‚Äîbelieving that open-source software is an ideal contribution to scientific communities that value transparency and reproducibility.
I enjoy watching movies and hunting for new places whenever I travel in my free time.
I'm always curious to meet new people and hear about their journeys, so shoot me an email or DM me on any social media!


<details>
<summary style="margin-left: 1em;"><b>CS PhD @ USC ‚úåÔ∏è</b></summary><div style="margin-left: 1em;">
The main problem I'm trying to solve is the integration of AI systems into human workflows‚Äîspecifically, answering the question: "What is the core part of a task that AI cannot do, and how can AI assist humans in doing that?"
Helping humans tackle the hardest parts of their jobs‚Äîwith AI as a consultant‚Äîis the overarching meta-goal of my current research.
To address this, I've explored several domains where large language models (LLMs) have been introduced but face full-integration challenges. These include software developers trusting code agents for programming, strategic decision-making in the board game Diplomacy, and patients navigating conflicting medical advice.
<br><br>
I'm currently in my second year and looking forward to exploring more domains to develop a taxonomy of these challenges and a framework that identifies the right interaction patterns and integration points for AI.
Throughout this journey, I've had the great opportunity to work with the Adaptive Computing Experience (ACE) Lab (Souti Chattopadhyay‚Äôs lab @ GCS) and [CUTE LAB NAME] (Jonathan May‚Äôs lab @ ISI).
<br><br>
You can find some of my publications below:
  <details>
    <summary style="margin-left: 1em;">[ICSE25] <b>Trust dynamics in AI-assisted development: Definitions, factors, and implications,</b> <b><u>Sadra Sabouri</u></b>, Philipp Eibl, Xinyi Zhou, Morteza Ziyadi, Nenad Medvidovic, Lars Lindemann, Souti Chattopadhyay</summary><div style="margin-left: 1em;">
    <a href="https://www.amazon.science/publications/trust-dynamics-in-ai-assisted-development-definitions-factors-and-implications" style="text-decoration: none;"><div style="display: inline-block;padding: 6px 12px;background-color: #007BFF;color: white;border-radius: 4px;font-size: 14px;text-align: center;cursor: pointer;">Paper</div></a><br>
    We investigate how developers define, evaluate, and evolve trust in AI-generated code suggestions through a mixed-method study involving surveys and observations. We found that while comprehensibility and perceived correctness are key to trust decisions, developers often revise their choices, accepting only 52% of AI suggestions, highlighting the need for better real-time support and offering four validated guidelines to improve developer-AI collaboration.
  </div></details>
  <details>
    <summary style="margin-left: 1em;">[ACL25] <b>ELI-Why: Evaluating the Pedagogical Utility of Language Model Explanations,</b> Brihi Joshi, Keyu He, Sahana Ramnath, <b><u>Sadra Sabouri</u></b>, Kaitlyn Zhou, Souti Chattopadhyay, Swabha Swayamdipta, Xiang Ren</summary><div style="margin-left: 1em;">
    <a href="https://arxiv.org/pdf/2506.14200" style="text-decoration: none;"><div style="display: inline-block;padding: 6px 12px;background-color: #007BFF;color: white;border-radius: 4px;font-size: 14px;text-align: center;cursor: pointer;">Paper</div></a>
    <a href="https://github.com/INK-USC/ELI-Why" style="text-decoration: none;"><div style="display: inline-block;padding: 6px 12px;background-color: #007BFF;color: white;border-radius: 4px;font-size: 14px;text-align: center;cursor: pointer;">Code</div></a>
    <a href="https://huggingface.co/collections/INK-USC/eli-why-6849086c86556f7a2dd7c686" style="text-decoration: none;"><div style="display: inline-block;padding: 6px 12px;background-color: #007BFF;color: white;border-radius: 4px;font-size: 14px;text-align: center;cursor: pointer;">Data</div></a><br>
    We investigate how well language models adapt explanations to learners with varying educational backgrounds using ELI-Why, a benchmark of 13.4K "Why" questions. Through two human studies, we found that GPT-4 explanations align with intended grade levels only 50% of the time and are rated 20% less suitable for learners‚Äô needs compared to layperson-curated responses, revealing limitations in their pedagogical adaptability.
  </div></details>
<br>
Always happy to chat, collaborate, or just hear what you're working on; feel free to reach out!
</div></details>

<hr>

<details>
<summary style="margin-left: 1em;"><b>Open World Developer üåê</b></summary><div style="margin-left: 1em;">
Open-sourcing research in NLP has lead to breakthroughs like ChatGPT, but generative AI also makes it easier to produce convincing yet flawed content in research communities.
This poses a sense of Frankenstein-Trojan threat to scientific integrity.
Committed to open science and reproducibility, I focus on building scientific software that ensures transparency.
With a group of my friends, I co-founded <a href="https://github.com/openscilab/">OpenSciLab</a> to develop open-source tools toward this goal.
<br><br>
Below is a topic-based summary of my work, both through OpenSciLab and independent projects: [TBD]
  <details>
    <summary style="margin-left: 1em;">Natural Language Processing (NLP) and Speech Processing</summary><div style="margin-left: 1em;">
    memor, parsipy, nava, naab, syntran-fa, speech-review, wav2vec2, pahgen, xnum, p-in-court, docalog, exprand, tocount
  </div></details>
  <details>
    <summary style="margin-left: 1em;">Machine Learning (ML)</summary><div style="margin-left: 1em;">
    PyCM, 2bfair
  </div></details>
  <details>
    <summary style="margin-left: 1em;">Network</summary><div style="margin-left: 1em;">
    pyrgg, ipspot, Pymilo, dmeta, mybutton, reserver
  </div></details>
  <details>
    <summary style="margin-left: 1em;">Art</summary><div style="margin-left: 1em;">
    art, samila
  </div></details>
  <details>
    <summary style="margin-left: 1em;">Human Computer Interaction (HCI)</summary><div style="margin-left: 1em;">
    Nafas, mytimer
  </div></details>
  <details>
    <summary style="margin-left: 1em;">Chemistry</summary><div style="margin-left: 1em;">
    ECSIMs,
    ECSIM-dataset
  </div></details>
  <details>
    <summary style="margin-left: 1em;">Biomedical Science</summary><div style="margin-left: 1em;">
      <!-- drux -->
      <details>
        <summary style="margin-left: 1em;">OPR: Optimized Primer Design Tool</summary><div style="margin-left: 1em;">
        <a href="https://github.com/openscilab/opr" style="text-decoration: none;"><div style="display: inline-block;padding: 6px 12px;background-color: #007BFF;color: white;border-radius: 4px;font-size: 14px;text-align: center;cursor: pointer;">GitHub</div></a>
        <img src="https://img.shields.io/github/stars/openscilab/opr.svg?style=social&logo=github&label=Stars">
        <img src="https://img.shields.io/github/forks/openscilab/opr.svg?style=social&logo=github&label=Forks">
        <a href="http://pepy.tech/project/opr"><img src="http://pepy.tech/badge/opr"></a><br>
        OPR is an open-source Python package designed to simplify and streamline primer design and analysis for biologists and bioinformaticians. It enables users to design, validate, and optimize primers with ease, catering to a wide range of applications such as PCR, qPCR, and sequencing. 
      </div></details>
  </div></details>
  <details>
    <summary style="margin-left: 1em;">Civil Engineering</summary><div style="margin-left: 1em;">
      <details>
        <summary style="margin-left: 1em;">[AGU-WRR24] <b>Representative sample size for estimating saturated hydraulic conductivity via machine learning: A proof‚Äêof‚Äêconcept study,</b> Amin Ahmadisharaf, Reza Nematirad, <b><u>Sadra Sabouri</u></b>, Yakov Pachepsky, Behzad Ghanbarian</summary><div style="margin-left: 1em;">
        <a href="https://agupubs.onlinelibrary.wiley.com/doi/pdfdirect/10.1029/2023WR036783" style="text-decoration: none;"><div style="display: inline-block;padding: 6px 12px;background-color: #007BFF;color: white;border-radius: 4px;font-size: 14px;text-align: center;cursor: pointer;">Paper</div></a><br>
        Machine learning is widely used across disciplines, but hydrology has often overlooked the impact of data heterogeneity and sample size. In this study, we used ~18k soil samples from the USKSAT database to analyze how training size affects ML accuracy in estimating saturated hydraulic conductivity (Ks). Using XGBoost and repeated random subsets, we found that even with large datasets, learning and validation curves didn‚Äôt plateau.
      </div></details>
  </div></details>
</div></details>

### News

Mar 2025: Python Software Foundation (PSF) granted our work, [Nava library](https://github.com/openscilab/nava), for adding new OS-based sound engines, and integrating into notebooks.

Feb 2025: Nlnet granted our work, [PyCM library](https://github.com/sepandhaghighi/pycm), for a year through NGI0 Commons Fund for adding new features such as distance similarity matrix, data distribution analysis, hardware benchmarking of the library.

Jan 2025: My paper [Trust dynamics in AI-assisted development: Definitions, factors, and implications](https://www.amazon.science/publications/trust-dynamics-in-ai-assisted-development-definitions-factors-and-implications) got accepted into International Conference on Software Engineering (ICSE) 2025. I will present my work remotely in searly May.

Sep 2024: I was awarded a [Trelis AI Grant](https://trelis.com/trelis-ai-grants/) for developing a RESTful API for PyCM, enhancing accessibility to machine learning statistical post-processing tools.

May 2024: Python Software Foundation (PSF) granted our work, [ASCII Art library](https://github.com/sepandhaghighi/art), for developing the library and add new features like multi-line arts, and supporting custom fonts.

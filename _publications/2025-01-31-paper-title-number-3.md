---
title: "Trust dynamics in AI-assisted development: Definitions, factors, and implications"
collection: publications
permalink: /publication/2022-08-29-paper-title-number-3
excerpt: 'Software developers increasingly rely on AI code generation utilities. To ensure that “good” code is accepted into the code base and “bad” code is rejected, developers must know when to trust an AI suggestion. Understanding how developers build this intuition is crucial to enhancing developer-AI collaborative programming. In this paper, we seek to understand how developers (1) define and (2) evaluate the trustworthiness of a code suggestion and (3) how trust evolves when using AI code assistants. To answer these questions, we conducted a mixedmethod study consisting of an in-depth exploratory survey with (n= 29) developers followed by an observation study (n= 10). We found that comprehensibility and perceived correctness were the most frequently used factors to evaluate code suggestion trustworthiness. However, the gap in developers’ definition and evaluation of trust points to a lack of support for evaluating trustworthy code in real-time. We also found that developers often alter their trust decisions, keeping only 52% of original suggestions. Based on these findings, we extracted four guidelines to enhance developer-AI interactions. We validated the guidelines through a survey with (n= 7) domain experts and survey members (n= 8). We discuss the validated guidelines, how to apply them, and tools to help adopt them.'
date: 2025-01-31
venue: 'International Conference on Software Engineering (ICSE) 2025'
paperurl: 'https://www.amazon.science/publications/trust-dynamics-in-ai-assisted-development-definitions-factors-and-implications'
citation: 'Sabouri, Sadra, Philipp Eibl, Xinyi Zhou, Morteza Ziyadi, Nenad Medvidovic, Lars Lindemann, and Souti Chattopadhyay. "Trust dynamics in AI-assisted development: Definitions, factors, and implications." (2025).'
---
Software developers increasingly rely on AI code generation utilities. To ensure that “good” code is accepted into the code base and “bad” code is rejected, developers must know when to trust an AI suggestion. Understanding how developers build this intuition is crucial to enhancing developer-AI collaborative programming. In this paper, we seek to understand how developers (1) define and (2) evaluate the trustworthiness of a code suggestion and (3) how trust evolves when using AI code assistants. To answer these questions, we conducted a mixedmethod study consisting of an in-depth exploratory survey with (n= 29) developers followed by an observation study (n= 10). We found that comprehensibility and perceived correctness were the most frequently used factors to evaluate code suggestion trustworthiness. However, the gap in developers’ definition and evaluation of trust points to a lack of support for evaluating trustworthy code in real-time. We also found that developers often alter their trust decisions, keeping only 52% of original suggestions. Based on these findings, we extracted four guidelines to enhance developer-AI interactions. We validated the guidelines through a survey with (n= 7) domain experts and survey members (n= 8). We discuss the validated guidelines, how to apply them, and tools to help adopt them.

[Download paper here](https://assets.amazon.science/99/78/f02aeaa049b4ba514d7f2790ade7/trust-dynamics-in-ai-assisted-development-definitions-factors-and-implications.pdf)
